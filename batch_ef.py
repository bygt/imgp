# batch_ef.py

import warnings
warnings.filterwarnings("ignore")

import torch
from PIL import Image
from torchvision import transforms
import numpy as np
import os
import multiprocessing as mp
from functools import partial
import time

# Load CLIP
import clip
from background_removal import preprocess_image_for_clothing

# Folder paths
image_dir = "static/images"
vector_dir = "vectors"

print("Loading models...")
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load DINOv2 - force offline mode
try:
    dino_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14', source='local').to(device)
except:
    # Try cached version
    dino_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14', force_reload=False).to(device)
dino_model.eval()

# Load CLIP
clip_model, clip_preprocess = clip.load("ViT-L/14", device=device)
clip_model.eval()
print("Models loaded.")

# DINO transform
dino_transform = transforms.Compose([
    transforms.Resize(518),
    transforms.CenterCrop(518),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

os.makedirs(vector_dir, exist_ok=True)

image_files = [f for f in os.listdir(image_dir) if f.lower().endswith((".jpg", ".jpeg", ".png"))]

print(f"{len(image_files)} images found.\n")

def process_single_image(args):
    """Tek bir gÃ¶rseli iÅŸle"""
    filename, image_dir, vector_dir, dino_model, clip_model, clip_preprocess, dino_transform = args
    
    image_path = os.path.join(image_dir, filename)
    vector_path = os.path.join(vector_dir, os.path.splitext(filename)[0] + ".npy")
    
    if os.path.exists(vector_path):
        return f"Skipped (already exists): {filename}"
    
    try:
        # Load image without background removal for vector creation
        processed_image = preprocess_image_for_clothing(image_path, use_background_removal=False)
        
        # Load image for DINO
        dino_input = dino_transform(processed_image).unsqueeze(0).to(device)
        with torch.no_grad():
            dino_feat = dino_model(dino_input).squeeze().cpu().numpy()
        
        # Load image for CLIP with clothing focus
        clip_input = clip_preprocess(processed_image).unsqueeze(0).to(device)
        
        # KÄ±yafet odaklÄ± text promptlarÄ±
        text_prompts = [
            "clothing item",
            "fashion garment", 
            "shirt",
            "dress",
            "pants",
            "jacket",
            "sweater",
            "blouse"
        ]
        
        with torch.no_grad():
            # GÃ¶rsel Ã¶zellikler
            image_features = clip_model.encode_image(clip_input)
            
            # Text Ã¶zellikler
            text_tokens = clip.tokenize(text_prompts).to(device)
            text_features = clip_model.encode_text(text_tokens)
            text_features_mean = text_features.mean(dim=0, keepdim=True)
            
            # BirleÅŸtir
            alpha = 0.7  # GÃ¶rsel Ã¶zellik aÄŸÄ±rlÄ±ÄŸÄ±
            beta = 0.3   # Text Ã¶zellik aÄŸÄ±rlÄ±ÄŸÄ±
            combined_features = alpha * image_features + beta * text_features_mean
            
            clip_feat = combined_features.squeeze().cpu().numpy()
        
        # Normalize features separately
        dino_feat /= np.linalg.norm(dino_feat)
        clip_feat /= np.linalg.norm(clip_feat)
        
        # Concatenate features and normalize
        combined_feat = np.concatenate([dino_feat, clip_feat]).astype("float32")
        combined_feat /= np.linalg.norm(combined_feat) + 1e-12
        
        np.save(vector_path, combined_feat)
        return f"âœ“ Saved: {filename} -> {vector_path}"
        
    except Exception as e:
        return f"Error ({filename}): {e}"

# Multiprocessing ile iÅŸle
def process_images_parallel(image_files, image_dir, vector_dir, dino_model, clip_model, clip_preprocess, dino_transform):
    """GÃ¶rselleri paralel iÅŸle"""
    # CPU core sayÄ±sÄ±nÄ± al
    num_cores = min(mp.cpu_count(), 8)  # Maksimum 8 core kullan
    print(f"Using {num_cores} CPU cores for parallel processing...")
    
    # ArgÃ¼manlarÄ± hazÄ±rla
    args_list = [(filename, image_dir, vector_dir, dino_model, clip_model, clip_preprocess, dino_transform) 
                 for filename in image_files]
    
    # Paralel iÅŸle
    start_time = time.time()
    with mp.Pool(processes=num_cores) as pool:
        results = pool.map(process_single_image, args_list)
    
    # SonuÃ§larÄ± yazdÄ±r
    for result in results:
        print(result)
    
    end_time = time.time()
    print(f"\nâ±ï¸ Total processing time: {end_time - start_time:.2f} seconds")
    print(f"ğŸš€ Speed: {len(image_files) / (end_time - start_time):.2f} images/second")

# Multiprocessing ile paralel iÅŸle
print("ğŸš€ Starting parallel processing...")
process_images_parallel(image_files, image_dir, vector_dir, dino_model, clip_model, clip_preprocess, dino_transform)
